% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/lazyframe-frame.R
\name{lazyframe__sink_ipc}
\alias{lazyframe__sink_ipc}
\title{Evaluate the query in streaming mode and write to an IPC file}
\usage{
lazyframe__sink_ipc(
  path,
  ...,
  compression = c("zstd", "lz4", "uncompressed"),
  maintain_order = TRUE,
  type_coercion = TRUE,
  predicate_pushdown = TRUE,
  projection_pushdown = TRUE,
  simplify_expression = TRUE,
  slice_pushdown = TRUE,
  no_optimization = FALSE,
  storage_options = NULL,
  retries = 2
)
}
\arguments{
\item{path}{A character. File path to which the file should be written.}

\item{...}{Dots which should be empty.}

\item{compression}{\code{NULL} or one of:
\itemize{
\item \code{"uncompressed"}: same as \code{NULL}.
\item \code{"lz4"}: fast compression/decompression.
\item \code{"zstd"}: good compression performance.
}}

\item{maintain_order}{Maintain the order in which data is processed. Setting
this to \code{FALSE} will be slightly faster.}

\item{type_coercion}{Logical. Coerce types such that operations succeed and
run on minimal required memory.}

\item{predicate_pushdown}{Logical. Applies filters as early as possible at
scan level.}

\item{projection_pushdown}{Logical. Select only the columns that are needed
at the scan level.}

\item{simplify_expression}{Logical. Various optimizations, such as constant
folding and replacing expensive operations with faster alternatives.}

\item{slice_pushdown}{Logical. Only load the required slice from the scan
level. Don't materialize sliced outputs (e.g. \code{join$head(10)}).}

\item{storage_options}{Named vector containing options that indicate how to
connect to a cloud provider. The cloud providers currently supported are
AWS, GCP, and Azure.
See supported keys here:
\itemize{
\item \href{https://docs.rs/object_store/latest/object_store/aws/enum.AmazonS3ConfigKey.html}{aws}
\item \href{https://docs.rs/object_store/latest/object_store/gcp/enum.GoogleConfigKey.html}{gcp}
\item \href{https://docs.rs/object_store/latest/object_store/azure/enum.AzureConfigKey.html}{azure}
\item Hugging Face (\verb{hf://}): Accepts an API key under the token parameter
\code{c(token = YOUR_TOKEN)} or by setting the \code{HF_TOKEN} environment
variable.
}

If \code{storage_options} is not provided, Polars will try to infer the
information from environment variables.}

\item{retries}{Number of retries if accessing a cloud instance fails.}
}
\value{
Invisibly returns the input LazyFrame
}
\description{
\ifelse{html}{\href{https://lifecycle.r-lib.org/articles/stages.html#experimental}{\figure{lifecycle-experimental.svg}{options: alt='[Experimental]'}}}{\strong{[Experimental]}}

This allows streaming results that are larger than RAM to be written to disk.
}
\examples{
# sink table 'mtcars' from mem to ipc
tmpf <- tempfile()
as_polars_lf(mtcars)$sink_ipc(tmpf)

# stream a query end-to-end (not supported yet, https://github.com/pola-rs/polars/issues/1040)
# tmpf2 = tempfile()
# pl$scan_ipc(tmpf)$select(pl$col("cyl") * 2)$sink_ipc(tmpf2)

# load ipc directly into a DataFrame / memory
# pl$scan_ipc(tmpf2)$collect()
}
